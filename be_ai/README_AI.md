# AI Assistant with OCR and RAG

Há»‡ thá»‘ng AI Assistant tÃ­ch há»£p OCR vÃ  RAG (Retrieval-Augmented Generation) Ä‘á»ƒ xá»­ lÃ½ vÃ  truy váº¥n tÃ i liá»‡u.

## ğŸ¯ TÃ­nh nÄƒng

### 1. **OCR Module** (`core/OCR/OCR.py`)
- TrÃ­ch xuáº¥t vÄƒn báº£n tá»« áº£nh (PNG, JPG, etc.)
- TrÃ­ch xuáº¥t vÄƒn báº£n tá»« PDF (tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i thÃ nh áº£nh)
- LÆ°u áº£nh tá»« PDF vÃ o thÆ° má»¥c `temp/`
- Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
- Tiá»n xá»­ lÃ½ áº£nh Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c

### 2. **RAG Assistant** (`core/AIssistance/AIssistance.py`)
- Sá»­ dá»¥ng Gemini AI lÃ m core chatbot
- Vector hÃ³a tÃ i liá»‡u vá»›i ChromaDB
- Embeddings vá»›i Sentence Transformers
- Truy váº¥n ngá»¯ nghÄ©a (semantic search)
- TÃ­ch há»£p RAG Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i dá»±a trÃªn tÃ i liá»‡u

## ğŸ“¦ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t system dependencies (Arch Linux)
```bash
sudo pacman -S tesseract tesseract-data-eng tesseract-data-vie
```

### 2. CÃ i Ä‘áº·t Python packages
```bash
pip install -r requirements.txt
```

### 3. Thiáº¿t láº­p Gemini API Key
```bash
export GEMINI_API_KEY="your-api-key-here"
```

Hoáº·c táº¡o file `.env`:
```
GEMINI_API_KEY=your-api-key-here
```

## ğŸš€ Sá»­ dá»¥ng

### VÃ­ dá»¥ 1: OCR cÆ¡ báº£n
```python
from core.OCR.OCR import OCRProcessor

# Khá»Ÿi táº¡o OCR
ocr = OCRProcessor(lang='vie+eng')

# TrÃ­ch xuáº¥t text tá»« áº£nh
text = ocr.extract_text_from_image('document.png')
print(text)

# TrÃ­ch xuáº¥t text tá»« PDF (tá»± Ä‘á»™ng lÆ°u áº£nh vÃ o temp/)
text = ocr.extract_text_from_pdf('document.pdf')
print(text)
```

### VÃ­ dá»¥ 2: RAG Assistant cÆ¡ báº£n
```python
from core.AIssistance.AIssistance import GeminiRAGAssistant

# Khá»Ÿi táº¡o assistant
assistant = GeminiRAGAssistant()

# ThÃªm tÃ i liá»‡u vÃ o knowledge base
documents = [
    "Python lÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh báº­c cao.",
    "Machine Learning lÃ  nhÃ¡nh cá»§a AI.",
    "FastAPI lÃ  framework hiá»‡n Ä‘áº¡i cho Python."
]
assistant.add_documents_to_knowledge_base(documents)

# Truy váº¥n
result = assistant.query("Python lÃ  gÃ¬?")
print(result['answer'])
```

### VÃ­ dá»¥ 3: TÃ­ch há»£p OCR + RAG
```python
from core.OCR.OCR import OCRProcessor
from core.AIssistance.AIssistance import GeminiRAGAssistant

# Khá»Ÿi táº¡o
ocr = OCRProcessor(lang='vie+eng')
assistant = GeminiRAGAssistant(collection_name="my_documents")

# TrÃ­ch xuáº¥t text tá»« PDF
text = ocr.extract_text_from_pdf('document.pdf')

# ThÃªm vÃ o knowledge base
metadata = {'filename': 'document.pdf', 'type': 'pdf'}
assistant.add_documents_to_knowledge_base(text, [metadata])

# Truy váº¥n
result = assistant.query("TÃ³m táº¯t ná»™i dung tÃ i liá»‡u")
print(result['answer'])
```

### VÃ­ dá»¥ 4: Cháº¡y demo Ä‘áº§y Ä‘á»§
```bash
python example_ocr_rag.py
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
Ai4SE/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ OCR/
â”‚   â”‚   â””â”€â”€ OCR.py              # Module OCR
â”‚   â””â”€â”€ AIssistance/
â”‚       â””â”€â”€ AIssistance.py      # Module RAG Assistant
â”œâ”€â”€ temp/                        # áº¢nh tá»« PDF
â”‚   â””â”€â”€ {pdf_name}/
â”‚       â”œâ”€â”€ {pdf_name}_page_1.png
â”‚       â””â”€â”€ {pdf_name}_page_2.png
â”œâ”€â”€ chroma_db/                   # Vector database
â”œâ”€â”€ example_ocr_rag.py          # Demo tÃ­ch há»£p
â”œâ”€â”€ requirements.txt
â””â”€â”€ README_AI.md                # File nÃ y
```

## ğŸ”§ API Reference

### OCRProcessor

#### `__init__(lang='vie+eng')`
Khá»Ÿi táº¡o OCR processor

#### `extract_text_from_image(image_source, preprocess=True)`
TrÃ­ch xuáº¥t text tá»« áº£nh hoáº·c PDF (tá»± Ä‘á»™ng phÃ¡t hiá»‡n)

#### `extract_text_from_pdf(pdf_source, save_images=True, temp_dir="temp")`
TrÃ­ch xuáº¥t text tá»« PDF vá»›i tÃ¹y chá»n lÆ°u áº£nh

#### `extract_data(image_source)`
TrÃ­ch xuáº¥t text chi tiáº¿t vá»›i confidence vÃ  bounding boxes

### DocumentVectorizer

#### `__init__(collection_name, persist_directory, embedding_model)`
Khá»Ÿi táº¡o vectorizer

#### `add_document(text, metadata, doc_id)`
ThÃªm 1 tÃ i liá»‡u

#### `add_documents(texts, metadatas, doc_ids)`
ThÃªm nhiá»u tÃ i liá»‡u

#### `add_document_from_file(file_path, chunk_size, chunk_overlap)`
ThÃªm tÃ i liá»‡u tá»« file text vá»›i chunking

#### `search(query, n_results)`
TÃ¬m kiáº¿m tÃ i liá»‡u liÃªn quan

#### `get_collection_stats()`
Láº¥y thá»‘ng kÃª collection

### GeminiRAGAssistant

#### `__init__(api_key, model_name, vectorizer, collection_name)`
Khá»Ÿi táº¡o RAG assistant

#### `add_documents_to_knowledge_base(texts, metadatas)`
ThÃªm tÃ i liá»‡u vÃ o knowledge base

#### `add_documents_from_directory(directory, pattern, chunk_size)`
ThÃªm táº¥t cáº£ file text tá»« thÆ° má»¥c

#### `query(question, n_context_docs, temperature, max_tokens)`
Truy váº¥n vá»›i RAG, tráº£ vá» answer + sources

#### `chat(message, use_rag, n_context_docs)`
Chat Ä‘Æ¡n giáº£n

#### `get_knowledge_base_stats()`
Láº¥y thá»‘ng kÃª knowledge base

## ğŸ¨ Workflow Ä‘áº§y Ä‘á»§

```python
import os
from pathlib import Path
from core.OCR.OCR import OCRProcessor
from core.AIssistance.AIssistance import GeminiRAGAssistant

# 1. Khá»Ÿi táº¡o
os.environ['GEMINI_API_KEY'] = 'your-key'
ocr = OCRProcessor(lang='vie+eng')
assistant = GeminiRAGAssistant(collection_name="documents")

# 2. Xá»­ lÃ½ tÃ i liá»‡u
documents_path = Path("documents")

for file_path in documents_path.glob("**/*.pdf"):
    # TrÃ­ch xuáº¥t text
    text = ocr.extract_text_from_pdf(str(file_path))
    
    # ThÃªm metadata
    metadata = {
        'filename': file_path.name,
        'path': str(file_path),
        'type': 'pdf'
    }
    
    # LÆ°u vÃ o knowledge base
    assistant.add_documents_to_knowledge_base(text, [metadata])

# 3. Truy váº¥n
questions = [
    "TÃ³m táº¯t cÃ¡c tÃ i liá»‡u",
    "CÃ³ nhá»¯ng thÃ´ng tin gÃ¬ vá» AI?",
    "Giáº£i thÃ­ch vá» Machine Learning"
]

for q in questions:
    result = assistant.query(q, n_context_docs=5)
    print(f"Q: {q}")
    print(f"A: {result['answer']}\n")
```

## ğŸ”‘ Láº¥y Gemini API Key

1. Truy cáº­p: https://makersuite.google.com/app/apikey
2. Táº¡o API key má»›i
3. Copy vÃ  set vÃ o environment variable

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Thay Ä‘á»•i embedding model
```python
from core.AIssistance.AIssistance import DocumentVectorizer

vectorizer = DocumentVectorizer(
    embedding_model="paraphrase-multilingual-MiniLM-L12-v2"  # Tá»‘t hÆ¡n cho tiáº¿ng Viá»‡t
)
```

### Thay Ä‘á»•i Gemini model
```python
assistant = GeminiRAGAssistant(
    model_name="gemini-1.5-pro"  # Model máº¡nh hÆ¡n
)
```

### Chunking strategy
```python
# Chunk nhá» hÆ¡n cho vÄƒn báº£n ngáº¯n
vectorizer.add_document_from_file(
    "document.txt",
    chunk_size=500,
    chunk_overlap=100
)
```

## ğŸ“Š Performance Tips

1. **OCR**: Sá»­ dá»¥ng `dpi=300` cho PDF cháº¥t lÆ°á»£ng cao
2. **Embeddings**: Model nhá» hÆ¡n = nhanh hÆ¡n nhÆ°ng Ã­t chÃ­nh xÃ¡c hÆ¡n
3. **ChromaDB**: Tá»± Ä‘á»™ng persist, khÃ´ng cáº§n save thá»§ cÃ´ng
4. **Chunking**: Chunk lá»›n = context tá»‘t, chunk nhá» = tÃ¬m kiáº¿m chÃ­nh xÃ¡c

## ğŸ› Troubleshooting

### Lá»—i "GEMINI_API_KEY not found"
```bash
export GEMINI_API_KEY="your-key"
```

### Lá»—i Tesseract
```bash
# CÃ i Ä‘áº·t láº¡i
sudo pacman -S tesseract tesseract-data-vie
```

### Lá»—i ChromaDB
```bash
# XÃ³a vÃ  táº¡o láº¡i
rm -rf chroma_db/
```

## ğŸ“ License

MIT License

## ğŸ‘¥ Contributors

- Your Name

## ğŸ”— Links

- Gemini API: https://ai.google.dev/
- ChromaDB: https://www.trychroma.com/
- Pytesseract: https://github.com/madmaze/pytesseract
